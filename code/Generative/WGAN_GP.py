# -*- coding: utf-8 -*-
"""WGAN_GP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QZ99yMNB0ky8TUe_oLKjdyhjw1sANruz
"""

######################################################## initial part is same as GAN.py, training is changed ##############################################3
!pip install opendatasets
import opendatasets as od
dataset_url = 'https://www.kaggle.com/splcher/animefacedataset'
od.download(dataset_url)


from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as T
import torch


image_size = 64
batch_size = 64
stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)
DATA_DIR = './animefacedataset'
dataset = ImageFolder(DATA_DIR, transform=T.Compose([
    T.Resize(image_size),
    T.CenterCrop(image_size),
    T.ToTensor(),
    T.Normalize(*stats)]))


from torch.utils.data import random_split
random_seed = 271828
torch.manual_seed(random_seed)
exclude_images = 33000
train_size = len(dataset) - exclude_images
train_ds, exclude_ds = random_split(dataset, [train_size, exclude_images])
train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)


# Commented out IPython magic to ensure Python compatibility.
import torch
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
# %matplotlib inline
def denorm(img_tensors):
    return img_tensors * stats[1][0] + stats[0][0]
def show_images(images, nmax=64):
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))
def show_batch(dl, nmax=64):
    for images, _ in dl:
        show_images(images, nmax)
        break
show_batch(train_dl)


def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')

def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)


device = get_default_device()
train_dl = DeviceDataLoader(train_dl, device)


import torch.nn as nn
discriminator = nn.Sequential(
    # in: 3 x 64 x 64

    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(64),
    nn.LeakyReLU(0.2, inplace=True),
    # out: 64 x 32 x 32

    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(128),
    nn.LeakyReLU(0.2, inplace=True),
    # out: 128 x 16 x 16

    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(256),
    nn.LeakyReLU(0.2, inplace=True),
    # out: 256 x 8 x 8

    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(512),
    nn.LeakyReLU(0.2, inplace=True),
    # out: 512 x 4 x 4

    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),
    # out: 1 x 1 x 1
    nn.Flatten())

discriminator = to_device(discriminator, device)


latent_size = 128
generator = nn.Sequential(
    # in: latent_size x 1 x 1

    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),
    # nn.BatchNorm2d(512),
    nn.ReLU(True),
    # out: 512 x 4 x 4

    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(256),
    nn.ReLU(True),
    # out: 256 x 8 x 8

    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(128),
    nn.ReLU(True),
    # out: 128 x 16 x 16

    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),
    # nn.BatchNorm2d(64),
    nn.ReLU(True),
    # out: 64 x 32 x 32

    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),
    nn.Tanh()
    # out: 3 x 64 x 64
)


xb = torch.randn(batch_size, latent_size, 1, 1)
fake_images = generator(xb)
print(fake_images.shape)
show_images(fake_images)

generator = to_device(generator, device)


from torchvision.utils import save_image
import os
sample_dir = 'generated'
os.makedirs(sample_dir, exist_ok=True)
def save_samples(index, latent_tensors, show=True):
    fake_images = generator(latent_tensors)
    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)
    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)
    print('Saving', fake_fname)
    if show:
        fig, ax = plt.subplots(figsize=(8, 8))
        ax.set_xticks([]); ax.set_yticks([])
        ax.imshow(make_grid(denorm(fake_images).cpu().detach(), nrow=8).permute(1, 2, 0))


fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)
save_samples(0, fixed_latent)


from tqdm.notebook import tqdm
import torch.nn.functional as F

def gradient_penalty(disc, real_img, fake_img, LAMDA=10, cuda=True):
    batch_size = real_img.size(0)
    alpha = torch.rand(batch_size, 1)
    alpha= alpha.expand(batch_size, real_img.nelement()//batch_size).reshape(real_img.shape)
    if cuda:
        alpha = alpha.cuda()
    x = (alpha * real_img + (1-alpha) * fake_img).requires_grad_(True)
    if cuda:
        x = x.cuda()
    out = disc(x)

    grad_outputs = torch.ones(out.shape)
    if cuda:
        grad_outputs = grad_outputs.cuda()

    gradients = torch.autograd.grad(outputs=out, inputs=x, grad_outputs=grad_outputs, create_graph=True, only_inputs=True)[0]
    gradients = gradients.reshape(batch_size, -1)

    return LAMDA * ((gradients.norm(2, dim=1)-1)**2).mean()

def fit(epochs, lr, start_idx=1):
    torch.cuda.empty_cache()

    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9))
    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))

    for epoch in range(epochs):
        i = 0
        for real_images, _ in tqdm(train_dl):
            current_batch_size = real_images.shape[0]
            real_images = real_images.to(device)

            latent = torch.randn(current_batch_size, latent_size, 1, 1, device=device)

            discriminator.zero_grad()
            loss_real = -discriminator(real_images).mean()
            fake_img = generator(latent).detach()
            loss_fake = discriminator(fake_img).mean()
            gp = gradient_penalty(discriminator, real_images.detach(), fake_img, LAMDA=10)
            loss_d = loss_real + loss_fake + gp
            loss_d.backward()
            opt_d.step()

            z = torch.randn(current_batch_size, latent_size, 1, 1, device=device)

            if (i % 6 == 0):
                generator.zero_grad()
                loss_g = -discriminator(generator(z)).mean()
                loss_g.backward()
                opt_g.step()


        print("Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}".format(
            epoch+1, epochs, loss_g, loss_d))
        save_samples(epoch+start_idx, fixed_latent, show=False)

lr = 0.0005
epochs = 10

fit(epochs, lr)
